# ğŸ§  Emotion Detector â€” Facial Emotion Recognition in Real Time

**Reconoce emociones humanas en tiempo real usando IA y visiÃ³n por computadora.**  
Un proyecto construido con **TensorFlow.js**, **MediaPipe FaceMesh** y **React**, que combina *machine learning* y *front-end interactivo*.

---

## ğŸ“– DescripciÃ³n

**Emotion Detector** es un proyecto de detecciÃ³n de emociones faciales basado en aprendizaje profundo.  
El modelo fue entrenado con el dataset **FER2013**, procesando imÃ¡genes de rostros para clasificar emociones humanas en siete categorÃ­as:  

ğŸ˜ Neutral Â· ğŸ˜€ Feliz Â· ğŸ˜¢ Triste Â· ğŸ˜  Enojado Â· ğŸ˜® Sorprendido Â· ğŸ˜¨ Miedo Â· ğŸ¤¢ Asco  

El flujo principal combina dos componentes:

- **MediaPipe FaceMesh**: detecta 468 puntos (*landmarks*) en el rostro humano y los convierte en datos numÃ©ricos.  
- **TensorFlow.js**: recibe esos datos como tensores y predice la emociÃ³n correspondiente con un modelo de red neuronal entrenado en Python y exportado a formato `.json` para usarse en la web.

---

## âš™ï¸ TecnologÃ­as utilizadas

| Ãrea | TecnologÃ­as |
|------|-------------|
| Frontend | React + Vite |
| IA / ML | TensorFlow (Python) Â· TensorFlow.js |
| VisiÃ³n por computadora | MediaPipe FaceMesh |
| Preprocesamiento | NumPy Â· PIL (Python Imaging Library) |
| Backend opcional | Node.js (para despliegues locales o APIs auxiliares) |

---

## ğŸ§© CÃ³mo funciona

### Entrenamiento del modelo (Python)

- Se usÃ³ el dataset **FER2013** con imÃ¡genes de 48x48 pÃ­xeles en escala de grises.  
- El modelo es una red neuronal densa: `Dense(128) â†’ Dense(64) â†’ Dense(7, softmax)`  
- Tras el entrenamiento, se exportÃ³ con `model.export("emotion_model")` para su uso en TensorFlow.js.

### PredicciÃ³n en tiempo real (JavaScript)

- El navegador detecta tu rostro con **FaceMesh**.  
- Convierte los *landmarks* en un tensor (`tf.tensor2d`) del tamaÃ±o esperado por el modelo.  
- **TensorFlow.js** predice la emociÃ³n y la dibuja sobre el video en vivo.

---

## ğŸš€ CÃ³mo usarlo

### ğŸ§© 1. Clonar el repositorio

```bash
git clone https://github.com/maaquin/EmotionDetector.git
cd EmotionDetector
```

### âš™ï¸ 2. Instalar dependencias
```bash
npm install
```

### â–¶ï¸ 4. Ejecutar el proyecto
```bash
npm run dev
```
- Luego abre tu navegador en http://localhost:5173

## ğŸŒ Despliegue
- Enlace al proyecto desplegado: [Por agregar]

---

## âœ¨ Notas
- **Compatibilidad del navegador:** El proyecto funciona mejor en navegadores modernos que soporten WebGL 2.0 y WebAssembly.
- **Rendimiento:** La predicciÃ³n en tiempo real puede variar segÃºn la cÃ¡mara y CPU/GPU del dispositivo. Para mejorar la velocidad se puede reducir la resoluciÃ³n del video o usar un modelo mÃ¡s ligero.
- **PrecisiÃ³n del modelo:** El modelo actual es un MLP (red densa) entrenado con FER2013. Puede confundirse con emociones similares; usar CNNs mejorarÃ­a el reconocimiento.
- **Seguridad y privacidad:** Todo el procesamiento ocurre en el navegador; las imÃ¡genes de video no se envÃ­an a servidores externos.
- **Extensiones futuras:** Se puede integrar con sistemas de anÃ¡lisis de emociones, chatbots o apps de psicologÃ­a/educaciÃ³n.
- **Errores comunes:** Si model.predict lanza un error de shape, revisa que los landmarks se conviertan correctamente en un tensor de tamaÃ±o [1, 2304].

---

## ğŸ“Œ Autor
- Luciano Maquin â€“ [@Maaquin](https://github.com/maaquin)